Creating sequence-to-sequences 
with attention mechanism 

2016-08-08 20:03:10.157469
 2 layers of 512 units  2 context size 128 bach-size. 
 128 batch size 2542 number of steps to complete one epoch 
global step 100 learning rate 0.0010 step-time 0.08 loss 1.89  perplexity 6.62 
global step 200 learning rate 0.0010 step-time 0.07 loss 1.45  perplexity 4.28 
global step 300 learning rate 0.0010 step-time 0.07 loss 1.35  perplexity 3.86 
global step 400 learning rate 0.0010 step-time 0.07 loss 1.28  perplexity 3.60 
global step 500 learning rate 0.0010 step-time 0.07 loss 1.22  perplexity 3.39 
global step 600 learning rate 0.0010 step-time 0.07 loss 1.19  perplexity 3.28 
global step 700 learning rate 0.0010 step-time 0.07 loss 1.19  perplexity 3.28 
global step 800 learning rate 0.0010 step-time 0.07 loss 1.17  perplexity 3.23 
global step 900 learning rate 0.0010 step-time 0.07 loss 1.16  perplexity 3.18 
global step 1000 learning rate 0.0010 step-time 0.07 loss 1.16  perplexity 3.18 
global step 1100 learning rate 0.0010 step-time 0.07 loss 1.16  perplexity 3.18 
global step 1200 learning rate 0.0010 step-time 0.07 loss 1.16  perplexity 3.19 
global step 1300 learning rate 0.0010 step-time 0.07 loss 1.15  perplexity 3.15 
global step 1400 learning rate 0.0010 step-time 0.07 loss 1.15  perplexity 3.17 
global step 1500 learning rate 0.0010 step-time 0.07 loss 1.14  perplexity 3.14 
global step 1600 learning rate 0.0010 step-time 0.07 loss 1.14  perplexity 3.11 
global step 1700 learning rate 0.0010 step-time 0.07 loss 1.15  perplexity 3.16 
global step 1800 learning rate 0.0010 step-time 0.07 loss 1.14  perplexity 3.12 
global step 1900 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.10 
global step 2000 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 2100 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.10 
global step 2200 learning rate 0.0010 step-time 0.07 loss 1.14  perplexity 3.13 
global step 2300 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.11 
global step 2400 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.10 
global step 2500 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.08 
epoch  0 finished 
  train:  loss 1.1281 perplexity 3.0897 
  eval:  loss 1.1426 perplexity 3.1349 
global step 2600 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.11 
global step 2700 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.07 
global step 2800 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.10 
global step 2900 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.08 
global step 3000 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.09 
global step 3100 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.07 
global step 3200 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.05 
global step 3300 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.07 
global step 3400 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 3500 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 3600 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.06 
global step 3700 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 3800 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.11 
global step 3900 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.08 
global step 4000 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.08 
global step 4100 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 4200 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.09 
global step 4300 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 4400 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.06 
global step 4500 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 4600 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.10 
global step 4700 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.06 
global step 4800 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 4900 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.06 
global step 5000 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.05 
epoch  1 finished 
  train:  loss 1.1127 perplexity 3.0427 
  eval:  loss 1.1333 perplexity 3.1060 
global step 5100 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.08 
global step 5200 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 5300 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.07 
global step 5400 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.09 
global step 5500 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 5600 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 5700 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.02 
global step 5800 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.05 
global step 5900 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.07 
global step 6000 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.06 
global step 6100 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.06 
global step 6200 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.02 
global step 6300 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.09 
global step 6400 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.02 
global step 6500 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.06 
global step 6600 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 6700 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 6800 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.09 
global step 6900 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 7000 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.10 
global step 7100 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.05 
global step 7200 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.10 
global step 7300 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 7400 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.05 
global step 7500 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 7600 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
epoch  2 finished 
  train:  loss 1.1087 perplexity 3.0305 
  eval:  loss 1.1327 perplexity 3.1042 
global step 7700 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 7800 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 7900 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 2.99 
global step 8000 learning rate 0.0010 step-time 0.07 loss 1.13  perplexity 3.08 
global step 8100 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.02 
global step 8200 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.05 
global step 8300 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 8400 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.06 
global step 8500 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 8600 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.05 
global step 8700 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.05 
global step 8800 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.02 
global step 8900 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 9000 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 9100 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.02 
global step 9200 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 9300 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 2.99 
global step 9400 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.02 
global step 9500 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.02 
global step 9600 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 2.99 
global step 9700 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 9800 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 9900 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 10000 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 10100 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
epoch  3 finished 
  train:  loss 1.1055 perplexity 3.0206 
  eval:  loss 1.1336 perplexity 3.1068 
global step 10200 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 10300 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 10400 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.06 
global step 10500 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.05 
global step 10600 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 10700 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.02 
global step 10800 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 10900 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.05 
global step 11000 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.02 
global step 11100 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.02 
global step 11200 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 11300 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 11400 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.96 
global step 11500 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 11600 learning rate 0.0010 step-time 0.07 loss 1.07  perplexity 2.92 
global step 11700 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 11800 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.02 
global step 11900 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 12000 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 12100 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 12200 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 12300 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 12400 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 12500 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 12600 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 12700 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
epoch  4 finished 
  train:  loss 1.0983 perplexity 2.9990 
  eval:  loss 1.1263 perplexity 3.0841 
global step 12800 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.02 
global step 12900 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.08 
global step 13000 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 13100 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 13200 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.02 
global step 13300 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 13400 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.02 
global step 13500 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 13600 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 13700 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 13800 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.02 
global step 13900 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 14000 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.02 
global step 14100 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.96 
global step 14200 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 14300 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 14400 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 2.99 
global step 14500 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.04 
global step 14600 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.05 
global step 14700 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 14800 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 14900 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.94 
global step 15000 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 15100 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 15200 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
epoch  5 finished 
  train:  loss 1.0985 perplexity 2.9997 
  eval:  loss 1.1277 perplexity 3.0887 
global step 15300 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.96 
global step 15400 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 15500 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 15600 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.96 
global step 15700 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 15800 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 15900 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.93 
global step 16000 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 16100 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 16200 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 16300 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 2.99 
global step 16400 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 2.99 
global step 16500 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.02 
global step 16600 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 16700 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 16800 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 16900 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 17000 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.02 
global step 17100 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 17200 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 17300 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 17400 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.93 
global step 17500 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 17600 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 17700 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
epoch  6 finished 
  train:  loss 1.0976 perplexity 2.9970 
  eval:  loss 1.1285 perplexity 3.0911 
global step 17800 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.05 
global step 17900 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.03 
global step 18000 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 18100 learning rate 0.0010 step-time 0.07 loss 1.12  perplexity 3.06 
global step 18200 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 18300 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 18400 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.95 
global step 18500 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 18600 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 2.99 
global step 18700 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 2.99 
global step 18800 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 18900 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 19000 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 19100 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.95 
global step 19200 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.95 
global step 19300 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 19400 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 19500 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.02 
global step 19600 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 19700 learning rate 0.0010 step-time 0.07 loss 1.11  perplexity 3.05 
global step 19800 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 19900 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 20000 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 20100 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.95 
global step 20200 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.95 
global step 20300 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.96 
epoch  7 finished 
  train:  loss 1.0960 perplexity 2.9921 
  eval:  loss 1.1296 perplexity 3.0943 
global step 20400 learning rate 0.0010 step-time 0.07 loss 1.07  perplexity 2.92 
global step 20500 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 20600 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 20700 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.02 
global step 20800 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 20900 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 21000 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 21100 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.96 
global step 21200 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
global step 21300 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.98 
global step 21400 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.94 
global step 21500 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.96 
global step 21600 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.95 
global step 21700 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 21800 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 21900 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 22000 learning rate 0.0010 step-time 0.07 loss 1.08  perplexity 2.96 
global step 22100 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.99 
global step 22200 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 22300 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 2.99 
global step 22400 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 22500 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 22600 learning rate 0.0010 step-time 0.07 loss 1.09  perplexity 2.97 
global step 22700 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.01 
global step 22800 learning rate 0.0010 step-time 0.07 loss 1.10  perplexity 3.00 
epoch  8 finished 
  train:  loss 1.0948 perplexity 2.9885 
  eval:  loss 1.1283 perplexity 3.0905 
Stopped training after 9 epochs
best training loss 2.9885 best validation 3.0841 
  test:  loss 1.1238 perplexity 3.0766 
